from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)

encoding = tokenizer("We are very happy to show you the ğŸ¤— Transformers library.")
print(f'enconding: {encoding}')
# enconding: {
# 'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 
# 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
# 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
# }

##########################################
### nlptown/bert-base-multilingual-uncased-sentiment
##########################################
# - nlptown: ì´ ëª¨ë¸ì„ ê°œë°œí•˜ê³  ê³µê°œí•œ ì¡°ì§ ë˜ëŠ” ì‚¬ìš©ìì˜ ì´ë¦„
# - bert: ì´ ëª¨ë¸ì˜ ê¸°ë³¸ êµ¬ì¡°ê°€ BERT ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©
# - base: BERTì˜ ê¸°ë³¸ í¬ê¸° ë²„ì „ -'small'ë³´ë‹¤ í¬ê³  'large'ë³´ë‹¤ ì‘ì€ ëª¨ë¸
# - multilingual: ë‹¤êµ­ì–´ ì§€ì›
# - uncased: ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ìŒ
# - sentiment: ê°ì„± ë¶„ì„ - ê¸ì •/ë¶€ì •


##########################################
### ì…ë ¥ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥, padding, truncationë¡œ ê· ì¼í•œ ê¸¸ì´ì˜ ë°°ì¹˜ë¥¼ ë°˜í™˜
##########################################
pt_batch = tokenizer(
    ["We are very happy to show you the ğŸ¤— Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)

print(f'pt_batch: {pt_batch}')
# pt_batch: {
# 'input_ids': tensor([
#                       [  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100, 58263, 13299,   119,   102],
#                       [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,    102,     0,     0,     0]
#                     ]), 
# 'token_type_ids': tensor([
#                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
#                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
#                     ]), 
# 'attention_mask': tensor([
#                       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
#                       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]
#                      ])
# }